import os
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
import streamlit as st
from core.parser import PDFParser
from core.vector_store import VectorStore
from core.graph_store import GraphStore
from agents.graph_builder import GraphBuilder
from graph_flow import run_workflow
from utils.gemini_client import GeminiClient
import base64
import tempfile
import os
import logging
import hashlib
from datetime import datetime
import sys

# ... (Previous imports remain, ensuring hashlib is at top)

# Function to calculate file hash
def get_file_hash(file_bytes):
    md5_hash = hashlib.md5()
    md5_hash.update(file_bytes)
    return md5_hash.hexdigest()

# ... (Logging setup remains)
# Configure logging with explicit UTF-8 encoding
logging.basicConfig(level=logging.INFO, handlers=[])  # Clear existing handlers
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)

# File Handler with UTF-8
file_handler = logging.FileHandler('app_monitor.log', encoding='utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
root_logger.addHandler(file_handler)

# Stream Handler with UTF-8 (only if not already handled by Streamlit, but explicit is safer)
# We wrap stdout in a TextIOWrapper ensuring utf-8 if we want to be 100% sure,
# or simply trust sys.stdout.reconfigure() we added in gemini_client.
# But for StreamHandler, we can assume sys.stdout is safe now, OR we explicit set stream.
stream_handler = logging.StreamHandler(sys.stdout)
stream_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
root_logger.addHandler(stream_handler)
logger = logging.getLogger(__name__)

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå¸ƒå±€
st.set_page_config(
    page_title="IC/BCD å¤šæ¨¡æ€çŸ¥è¯†åº“ç³»ç»Ÿ",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS for Gemini-like UI
st.markdown("""
<style>
    /* Global Settings */
    [data-testid="stAppViewContainer"] {
        background-color: #0e1117;
        color: #e0e0e0;
    }
    
    /* Hide Header/Footer */
    header {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* Chat Container Styling */
    .stChatMessage {
        background-color: #1e1e1e;
        border-radius: 10px;
        padding: 10px;
        margin-bottom: 10px;
        border: 1px solid #333;
    }
    
    /* Input Box Styling - Fix to bottom and remove padding issues */
    .stChatInput {
        position: fixed;
        bottom: 0px;
        z-index: 1000;
        background-color: #0e1117;
        padding-bottom: 20px;
    }
    
    /* Enhance sidebar */
    [data-testid="stSidebar"] {
        background-color: #161b22;
        border-right: 1px solid #333;
    }
    
    /* Scrollbar */
    ::-webkit-scrollbar {
        width: 8px;
        height: 8px;
    }
    ::-webkit-scrollbar-track {
        background: #0e1117; 
    }
    ::-webkit-scrollbar-thumb {
        background: #333; 
        border-radius: 4px;
    }
    ::-webkit-scrollbar-thumb:hover {
        background: #555; 
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–å„ä¸ªæ¨¡å— (ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åˆå§‹åŒ–)
@st.cache_resource
def get_parser():
    return PDFParser()

@st.cache_resource
def get_vector_store():
    return VectorStore()

@st.cache_resource
def get_graph_store():
    return GraphStore()

@st.cache_resource
def get_graph_builder():
    return GraphBuilder()

@st.cache_resource
def get_gemini_client():
    return GeminiClient()

parser = get_parser()
vector_store = get_vector_store()
graph_store = get_graph_store()
graph_builder = get_graph_builder()
gemini_client = get_gemini_client()

# åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨ä¸Šä¼ çš„æ–‡ä»¶
if "temp_dir" not in st.session_state:
    st.session_state.temp_dir = tempfile.mkdtemp()

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = []

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "processing_complete" not in st.session_state:
    # Check if there are existing documents in the Knowledge Base
    try:
        # ä½¿ç”¨ç¼“å­˜çš„æ•°æ®è·å–å‡½æ•°ï¼Œé¿å…æ¯æ¬¡åˆ·æ–°éƒ½æŸ¥è¯¢æ•°æ®åº“
        @st.cache_data(ttl=10) # 10s TTL because ingestion might change it
        def fetch_docs_status():
             return get_graph_store().get_all_documents()
        
        existing_docs = fetch_docs_status()
        if existing_docs:
            st.session_state.processing_complete = True
            logger.info("[App] Found existing documents in Knowledge Base. Enabling chat.")
        else:
            st.session_state.processing_complete = False
    except Exception as e:
        logger.error(f"[App] Failed to check for existing documents: {str(e)}")
        st.session_state.processing_complete = False

# ä¸»ç•Œé¢ï¼šä½¿ç”¨ Tab åˆ†éš”
tab_qa, tab_kb = st.tabs(["ğŸ’¬ æ™ºèƒ½å¯¹è¯", "ğŸ“š çŸ¥è¯†åº“ç®¡ç†"])

# Tab 1: æ™ºèƒ½å¯¹è¯ (Original UI)
with tab_qa:
    # Use wider ratio for chat
    col1, col2 = st.columns([7, 3])
    
    # å·¦ä¾§ï¼šå¯¹è¯ç•Œé¢
    with col1:
        st.title("ğŸ§  IC/BCD å¤šæ¨¡æ€çŸ¥è¯†åº“ç³»ç»Ÿ")
        
        # æ˜¾ç¤ºå¤„ç†çŠ¶æ€ - Use toast instead of occupying space
        if not st.session_state.processing_complete:
            if st.session_state.uploaded_files:
                st.toast("è¯·ç‚¹å‡»ä¾§è¾¹æ 'å¤„ç†æ–‡ä»¶'æŒ‰é’®ä»¥å¼€å§‹å¯¹è¯", icon="âš ï¸")
            else:
                st.toast("è¯·å…ˆä¸Šä¼ å¹¶å¤„ç† PDF æ–‡ä»¶", icon="â„¹ï¸")
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # è¾“å…¥æ¡†
        # å…è®¸åœ¨æœ‰ Knowledge Base æ•°æ®çš„æƒ…å†µä¸‹ç›´æ¥æé—®ï¼ˆéœ€æ”¹è¿›é€»è¾‘ï¼Œå‡è®¾KBæœ‰æ•°æ®å³å¯ï¼‰
        # æš‚æ—¶ä¿æŒ strict: processing_complete å¿…é¡»ä¸º True
        if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", disabled=not st.session_state.processing_complete):
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            
            # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # ç”Ÿæˆå›ç­”
            with st.chat_message("assistant"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›ç­”..."):
                    logger.info(f"[é—®ç­”æµç¨‹] ========== å¼€å§‹å¤„ç†ç”¨æˆ·é—®é¢˜ ==========")
                    logger.info(f"[é—®ç­”æµç¨‹] ç”¨æˆ·é—®é¢˜: {prompt}")
                    
                    try:
                        # è¿è¡Œå·¥ä½œæµ
                        result = run_workflow(prompt)
                        logger.info(f"[é—®ç­”æµç¨‹] å·¥ä½œæµæ‰§è¡Œå®Œæˆ - å®¡è®¡é€šè¿‡: {result['audit_passed']}")
                        
                        # æ˜¾ç¤ºå›ç­”
                        st.markdown(result["generated_answer"])
                        
                        # æ˜¾ç¤ºå®¡è®¡ç»“æœ
                        if result["audit_passed"]:
                            st.success("âœ… å›ç­”å·²é€šè¿‡äº‹å®å®¡è®¡")
                        else:
                            st.error("âŒ å›ç­”æœªé€šè¿‡äº‹å®å®¡è®¡ï¼Œå·²è¿›è¡Œä¿®æ­£")
                        
                        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°èŠå¤©å†å²
                        st.session_state.chat_history.append({"role": "assistant", "content": result["generated_answer"]})
                    except Exception as e:
                        st.error(f"ç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                        logger.error(f"[é—®ç­”æµç¨‹] é”™è¯¯: {str(e)}")

    # å³ä¾§ï¼šPDF é¢„è§ˆ
    with col2:
        st.title("ğŸ“– PDF é¢„è§ˆ")
        if st.session_state.uploaded_files:
            selected_file = st.selectbox(
                "é€‰æ‹©è¦é¢„è§ˆçš„æ–‡ä»¶",
                [file.name for file in st.session_state.uploaded_files]
            )
            if selected_file:
                # Find the file object
                file_obj = next((f for f in st.session_state.uploaded_files if f.name == selected_file), None)
                if file_obj:
                    base64_pdf = base64.b64encode(file_obj.getvalue()).decode("utf-8")
                    pdf_display = f"<iframe src='data:application/pdf;base64,{base64_pdf}' width='100%' height='600' type='application/pdf'></iframe>"
                    st.markdown(pdf_display, unsafe_allow_html=True)
        else:
            st.info("é¢„è§ˆä»…å¯¹å½“å‰ä¸Šä¼ çš„æ–‡ä»¶æœ‰æ•ˆ")

# Helper function to process a single file
def process_file(file_path, file_name, file_bytes):
    try:
        file_hash = get_file_hash(file_bytes)
        file_size = len(file_bytes)
        
        # 1. Parse
        st.toast(f"æ­£åœ¨è§£ææ–‡ä»¶ï¼š{file_name}...", icon="ğŸ”„")
        # Check stop signal (though Streamlit rerun kills script, this is for manual checks if we used threads)
        
        document_blocks = parser.process_pdf(file_path, gemini_client)
        
        # 2. Graph
        st.toast(f"æ­£åœ¨æ„å»ºå›¾è°±ï¼š{file_name}...", icon="ğŸ•¸ï¸")
        graph_builder.build_graph_from_blocks(document_blocks, file_name)
        
        # 3. Vector
        st.toast(f"æ­£åœ¨æ·»åŠ åˆ°å‘é‡åº“ï¼š{file_name}...", icon="ğŸ’¾")
        for block in document_blocks:
            try:
                vector_store.add_document_block(block, file_name)
            except Exception as e:
                logger.warning(f"Failed to add block to vector store: {e}")
        
        # 4. Save Metadata
        graph_store.add_document(
            doc_hash=file_hash,
            filename=file_name,
            size=file_size,
            upload_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
        logger.info(f"[å¤„ç†æµç¨‹] æ–‡ä»¶å¤„ç†å®Œæˆå¹¶ä¿å­˜å…ƒæ•°æ®: {file_name}")
        st.toast(f"æ–‡ä»¶å¤„ç†å®Œæˆ: {file_name}", icon="âœ…")
        return True
    
    except BaseException as e:
        # Catch ALL exceptions, including Streamlit's ScriptRunner stops/reruns
        logger.warning(f"[å¤„ç†æµç¨‹] å¤„ç†è¢«ä¸­æ­¢æˆ–å¤±è´¥ {file_name}: {str(e)}")
        st.error(f"å¤„ç†ç”±äºé”™è¯¯æˆ–ç”¨æˆ·ä¸­æ­¢è€Œåœæ­¢: {file_name}")
        
        # CLEANUP: Delete partial data
        logger.info(f"[å¤„ç†æµç¨‹] æ­£åœ¨æ¸…ç†å·²å†™å…¥çš„æ•°æ®: {file_name}")
        try:
            graph_store.delete_document(file_name)
            vector_store.delete_by_file_name(file_name)
            logger.info(f"[å¤„ç†æµç¨‹] æ¸…ç†å®Œæˆ: {file_name}")
        except Exception as cleanup_error:
            logger.error(f"[å¤„ç†æµç¨‹] æ¸…ç†å¤±è´¥: {cleanup_error}")
            
        # Re-raise unless it's a standard Exception we want to swallow (we don't)
        raise e

# ... (Sidebar remains largely similar, just calling process_file)

# Tab 2: çŸ¥è¯†åº“ç®¡ç†
with tab_kb:
    st.header("ğŸ“š çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨")
    
    col_tools_1, col_tools_2 = st.columns([1, 4])
    with col_tools_1:
         if st.button("åˆ·æ–°åˆ—è¡¨"):
            st.rerun()
    
    docs = graph_store.get_all_documents()
    
    if not docs:
        st.info("çŸ¥è¯†åº“æš‚æ—¶ä¸ºç©º")
    else:
        # Header
        cols = st.columns([3, 2, 2, 2, 2])
        cols[0].markdown("**æ–‡ä»¶å**")
        cols[1].markdown("**ä¸Šä¼ æ—¶é—´**")
        cols[2].markdown("**å¤§å° (Bytes)**")
        cols[3].markdown("**çŠ¶æ€**")
        cols[4].markdown("**æ“ä½œ**")
        st.markdown("---")
        
        for doc in docs:
            cols = st.columns([3, 2, 2, 2, 2])
            filename = doc.get('filename', 'Unknown')
            
            cols[0].write(filename)
            cols[1].write(doc.get('upload_time', 'N/A'))
            cols[2].write(doc.get('size', 0))
            cols[3].write(doc.get('status', 'Unknown'))
            
            with cols[4]:
                c1, c2 = st.columns(2)
                with c1:
                    if st.button("ğŸ—‘ï¸", key=f"del_{filename}", help="åˆ é™¤æ–‡æ¡£"):
                        with st.spinner(f"æ­£åœ¨åˆ é™¤ {filename}..."):
                            # Delete from Graph
                            graph_store.delete_document(filename)
                            # Delete from Vector
                            vector_store.delete_by_file_name(filename)
                            st.success(f"å·²åˆ é™¤ {filename}")
                            st.rerun()
                
                with c2:
                    if st.button("ğŸ”„", key=f"reprocess_{filename}", help="é‡æ–°å¤„ç†"):
                        # Check if file exists in temp dir
                        temp_path = os.path.join(st.session_state.temp_dir, filename)
                        if os.path.exists(temp_path):
                            with st.spinner(f"æ­£åœ¨é‡æ–°å¤„ç† {filename}..."):
                                # 1. Delete existing data
                                graph_store.delete_document(filename)
                                vector_store.delete_by_file_name(filename)
                                
                                # 2. Reprocess
                                with open(temp_path, "rb") as f:
                                    file_bytes = f.read()
                                
                                if process_file(temp_path, filename, file_bytes):
                                    st.success(f"é‡æ–°å¤„ç†å®Œæˆ: {filename}")
                                    st.rerun()
                        else:
                            st.error("æºæ–‡ä»¶å·²ä¸¢å¤±ï¼Œè¯·é‡æ–°ä¸Šä¼ ")

# ä¾§è¾¹æ å¤„ç†é€»è¾‘æ›´æ–°
with st.sidebar:
    st.title("ğŸ“ æ–‡ä»¶ç®¡ç†")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼  PDF æ–‡ä»¶",
        type="pdf",
        accept_multiple_files=True
    )
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    if uploaded_files:
        for file in uploaded_files:
            if file not in st.session_state.uploaded_files:
                # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                safe_filename = os.path.basename(file.name)
                file_path = os.path.join(st.session_state.temp_dir, safe_filename)
                logger.info(f"[æ–‡ä»¶ä¸Šä¼ ] å¼€å§‹ä¿å­˜æ–‡ä»¶: {safe_filename}, å¤§å°: {file.size} bytes")
                with open(file_path, "wb") as f:
                    f.write(file.getvalue())
                logger.info(f"[æ–‡ä»¶ä¸Šä¼ ] æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")
                
                # æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.uploaded_files.append(file)
                logger.info(f"[æ–‡ä»¶ä¸Šä¼ ] æ–‡ä»¶å·²æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€: {file.name}")
    
    # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡ä»¶
    if st.session_state.uploaded_files:
        st.subheader("å·²ä¸Šä¼ çš„æ–‡ä»¶")
        for file in st.session_state.uploaded_files:
            st.write(f"âœ… {file.name}")
    
    col_proc_1, col_proc_2 = st.columns(2)
    with col_proc_1:
        start_processing = st.button("å¤„ç†æ–‡ä»¶", key="process_button", disabled=not st.session_state.uploaded_files)
    with col_proc_2:
        stop_processing = st.button("ä¸­æ­¢å¤„ç†", key="stop_button", type="primary")

    if stop_processing:
        st.warning("ç”¨æˆ·è¯·æ±‚ä¸­æ­¢å¤„ç†ã€‚")
        st.stop()

    if start_processing:
        with st.spinner("æ­£åœ¨æ‰¹é‡å¤„ç†æ–‡ä»¶... (ç‚¹å‡»'ä¸­æ­¢å¤„ç†'å¯åœæ­¢)"):
            logger.info(f"[å¤„ç†æµç¨‹] ========== å¼€å§‹ ... ==========")
            
            processed_any = False
            
            status_container = st.status("æ­£åœ¨å¤„ç†æ–‡ä»¶...", expanded=True)
            
            for file in st.session_state.uploaded_files:
                file_bytes = file.getvalue()
                file_hash = get_file_hash(file_bytes)
                
                # Check Deduplication
                existing_doc = graph_store.get_document(file_hash)
                if existing_doc:
                    st.toast(f"ğŸ“„ {file.name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                    status_container.write(f"Existing: {file.name}")
                    logger.info(f"[å¤„ç†æµç¨‹] æ–‡ä»¶è·³è¿‡ (å·²å­˜åœ¨): {file.name}")
                    continue
                
                # Process New File
                processed_any = True
                status_container.write(f"Processing: {file.name}")
                file_path = os.path.join(st.session_state.temp_dir, file.name)
                
                # Ensure file exists (it should, but just in case)
                if not os.path.exists(file_path):
                     with open(file_path, "wb") as f:
                        f.write(file_bytes)
                
                process_file(file_path, file.name, file_bytes)
            
            st.session_state.processing_complete = True
            status_container.update(label="æ‰¹é‡å¤„ç†å®Œæˆ!", state="complete", expanded=False)
            st.success("æ‰¹é‡å¤„ç†ç»“æŸï¼")
            if processed_any:
                st.rerun()


# é¡µè„š
st.markdown("---")
st.markdown("ğŸ“š åŸºäº LangGraph çš„ IC/BCD å¤šæ¨¡æ€çŸ¥è¯†åº“ç³»ç»Ÿ | 2024")
